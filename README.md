# NLP-LLM-Toolkits

## Core NLP Libraries
- NLTK (Natural Language Toolkit): A foundational library for symbolic and statistical NLP, offering tools for tokenization, stemming, tagging, parsing, and more
- spaCy: A modern, fast, and efficient library for advanced NLP tasks, excelling in tasks like named entity recognition, dependency parsing, and text classification
- TextBlob: A simplified library built on top of NLTK and pattern, providing easy-to-use interfaces for common NLP tasks
- Polyglot: A library for multilingual NLP, supporting a wide range of languages
- FastText: A library for efficient learning of word representations and sentence classification
- Gensim: A library focused on topic modeling and document similarity analysis
- 
## Deep Learning and Machine Learning Frameworks:
- Scikit-learn: A general-purpose machine learning library, offering a wide range of algorithms for classification, regression, clustering, and more
- TensorFlow: A powerful open-source machine learning framework, widely used for deep learning tasks
- TensorFlowText: 
- PyTorch: Another popular open-source machine learning framework, known for its flexibility and dynamic computation graph
- Keras: A high-level neural networks API, which can run on top of TensorFlow, or other backends

## Transformer-Based Libraries
- Transformers (Hugging Face): A comprehensive library for working with pre-trained transformer models for various NLP tasks via HuggingFace
- SentenceTransformers: A library specifically designed for computing dense vector representations of sentences and paragraphs
- Transformers.js: A javascript library to run transformer models in the browser

## LLM related tools
- LangChain: A framework for developing applications powered by language models, enabling chaining of LLM calls and integration with external data (RAG)
- LlamaIndex: A data framework for LLM applications, facilitating the connection of LLMs to external data sources (RAG)
- Haystack: An open-source framework for building search systems powered by LLMs
- Ollama: A tool to run LLMs locally
- vLLM: A high-throughput and memory-efficient inference and serving engine for LLMs
- Langfuse: An open source observability and analytics platform for LLMs
